{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from shapely.prepared import prep\n",
    "import geopandas\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data \n",
    "dataset = \"reanalysis-era5-single-levels\"\n",
    "request = {\"product_type\": [\"reanalysis\"], \"variable\": [\"2m_dewpoint_temperature\", \"2m_temperature\"], \"year\": [\"2024\", \"2025\"], \"month\": [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"], \"day\": [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"], \"time\": [\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\", \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\", \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"], \"data_format\": \"netcdf\", \"download_format\": \"zip\", \"area\": [51, -5, 41.5, 9.75]}\n",
    "client = cdsapi.Client()\n",
    "client.retrieve(dataset, request, \"2024-2025.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1940-1945.nc',\n",
       " '1946-1951.nc',\n",
       " '1952-1957.nc',\n",
       " '1958-1963.nc',\n",
       " '1964-1969.nc',\n",
       " '1970-1975.nc',\n",
       " '1976-1981.nc',\n",
       " '1982-1987.nc',\n",
       " '1988-1993.nc',\n",
       " '1994-1999.nc',\n",
       " '2000-2005.nc',\n",
       " '2006-2011.nc',\n",
       " '2012-2017.nc',\n",
       " '2018-2023.nc',\n",
       " '2024-2025.nc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [file for file in os.listdir(\"data/ERA5\") if file[-3:] == \".nc\"]\n",
    "files = sorted(files)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data of shape (n, x, y) with n the hour, x the latitude and y the longitude \n",
    "#we can find daily datas in the form (0:23, x, y), (24:47, x, y), (48:71, x, y)....\n",
    "#then make the calcalutions on the daily data, find the data points of each dep, find the day and finaly save the produces datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = geopandas.read_file(\"data/geojsonfrance_corse_20.json\") #read france departement geometries\n",
    "geo[\"code\"] = geo[\"code\"].astype(int)\n",
    "geo = geo.sort_values(by=\"code\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "data_index = 0\n",
    "points = dict()\n",
    "latitude = Dataset(\"data/ERA5/1940-1945.nc\").variables[\"latitude\"][:]\n",
    "longitude = Dataset(\"data/ERA5/1940-1945.nc\").variables[\"longitude\"][:]\n",
    "#for every lat and lon, we make a dict of index POINT(lon, lat) and value the index of the data associated with this point\n",
    "for lat in latitude:\n",
    "    for lon in longitude:\n",
    "        points[Point(lon, lat)] = data_index\n",
    "        data_index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-2023.nc\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for file in files[13:]:\n",
    "    print(file) #keep track of script\n",
    "    temp = Dataset(f\"data/ERA5/{file}\").variables[\"t2m\"][:] - 273.15 #convert to from Kelvin to Celsius\n",
    "    dewP = Dataset(f\"data/ERA5/{file}\").variables[\"d2m\"][:] - 273.15 #convert to from Kelvin to Celsius\n",
    "    rh = 100*(np.exp((17.625*dewP)/(243.04+dewP))/np.exp((17.625*temp)/(243.04+temp))) #August-Roche-Magnus equation to calculate relative humidity\n",
    "    vpd = 6.1078 * (1 - rh / 100) * np.exp(17.08085 * temp / (234.175 + temp)) * 0.1 #vpd in kPa #Alduchov, O. A., and R. E. Eskridge, 1996 formula\n",
    "    vpd = vpd.filled(np.nan) #replace masked values by NaN\n",
    "    \n",
    "    startYear = int(file[:4]) #get start year of each file\n",
    "    endYear = int(file[5:9]) #get end year of each file\n",
    "    date = datetime(startYear, 1, 1) #make a new datetime for the first day of the file\n",
    "    \n",
    "    #calculate how many complete days we have\n",
    "    total_hours = vpd.shape[0]\n",
    "    hours_per_day = 24\n",
    "    num_complete_days = total_hours // hours_per_day\n",
    "    \n",
    "    #loop through the array in 24-hour chunks\n",
    "    for day in range(num_complete_days):\n",
    "        #calculate start and end indices for this day\n",
    "        start_idx = day * hours_per_day       # 0, 24, 48, ...\n",
    "        end_idx = start_idx + hours_per_day   # 24, 48, 72, ...\n",
    "        \n",
    "        # Get the data for this day\n",
    "        dailyVpd = vpd[start_idx:end_idx]\n",
    "    \n",
    "        vpd_max = np.max(dailyVpd, axis=0)\n",
    "        vpd_max_flattened = vpd_max.flatten()\n",
    "        vpd_min = np.min(dailyVpd, axis=0)\n",
    "        vpd_min_flattened = vpd_min.flatten()\n",
    "        vpd_mean = np.mean(dailyVpd, axis=0)\n",
    "        vpd_mean_flattened = vpd_mean.flatten()\n",
    "    \n",
    "        for _, dep in geo.iterrows():\n",
    "            prepared = prep(dep[\"geometry\"]) #use prep for batch operations\n",
    "            valid_points = []\n",
    "            valid_points.extend(filter(prepared.contains, points)) #find POINTS in dep\n",
    "            valid_indices = [points[point] for point in valid_points if point in points] #make a list of valid points that are in the dep\n",
    "\n",
    "            if valid_indices:\n",
    "                vpd_max_dep = np.mean(vpd_max_flattened[valid_indices]) #find values with indices\n",
    "                vpd_mean_dep = np.mean(vpd_mean_flattened[valid_indices]) #find values with indices\n",
    "                vpd_min_dep = np.mean(vpd_min_flattened[valid_indices]) #find values with indices\n",
    "            else:\n",
    "                vpd_max_dep = np.nan\n",
    "                vpd_mean_dep = np.nan\n",
    "                vpd_min_dep = np.nan\n",
    "            \n",
    "            result.append({\"date\": date, \"departement\": dep[\"nom\"], \"dep\": dep[\"code\"], \"vpd_max\": float(vpd_max_dep), \"vpd_mean\": float(vpd_mean_dep), \"vpd_min\": float(vpd_min_dep)})\n",
    "        \n",
    "        date += timedelta(days=1) #append one day to datetime\n",
    "    df = pd.DataFrame(result)\n",
    "    df.to_csv(f\"data/ERA5/1940-{endYear}_vpd.csv\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
