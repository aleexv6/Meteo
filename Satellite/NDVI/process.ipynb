{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from shapely.prepared import prep\n",
    "import geopandas\n",
    "from config import NDVI_DATA_URL\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bit(arr, satellite=\"AVHRR\"):\n",
    "    if satellite == \"AVHRR\":\n",
    "        # bit mask 5.3 in doc : https://www.ncei.noaa.gov/pub/data/sds/cdr/CDRs/Normalized_Difference_Vegetation_Index/AVHRR/AlgorithmDescriptionAVHRR_01B-20b.pdf\n",
    "        mask_fixed_bits = np.uint16(0b0001111111011110)  # Où les bits fixes sont à 1\n",
    "        expected_values = np.uint16(0b0000000010000000)  # Les valeurs attendues pour ces bits fixes\n",
    "    elif satellite == \"VIIRS\":\n",
    "        #bit mask 4.3 in doc : https://www.ncei.noaa.gov/pub/data/sds/cdr/CDRs/Normalized_Difference_Vegetation_Index/VIIRS/AlgorithmDescriptionVIIRS_01B-20b.pdf\n",
    "        mask_fixed_bits = np.uint16(0b1000011101110111)  # Où les bits fixes sont à 1\n",
    "        expected_values = np.uint16(0b0000000001000000)  # Les valeurs attendues pour ces bits fixes\n",
    "    else:\n",
    "        print(\"Bad argument for QA\")\n",
    "        return \"\"\n",
    "    \n",
    "    # mask\n",
    "    return (arr & mask_fixed_bits) == expected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "points = dict()\n",
    "latitude = Dataset(f\"{NDVI_DATA_URL}/yearly_subsample/1981.nc\").variables[\"latitude\"][:]\n",
    "longitude = Dataset(f\"{NDVI_DATA_URL}/yearly_subsample/1981.nc\").variables[\"longitude\"][:]\n",
    "#for every lat and lon, we make a dict of index POINT(lon, lat) and value the index of the data associated with this point\n",
    "for lat in latitude:\n",
    "    for lon in longitude:\n",
    "        points[Point(lon, lat)] = data_index\n",
    "        data_index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = geopandas.read_file(\"geojsonfrance_corse_20.json\") #read france departement geometries\n",
    "geo[\"code\"] = geo[\"code\"].astype(int)\n",
    "geo = geo.sort_values(by=\"code\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for file in sorted(os.listdir(f\"{NDVI_DATA_URL}/yearly_subsample/\")):\n",
    "    year = file[:4]\n",
    "    ds = Dataset(f\"{NDVI_DATA_URL}/yearly_subsample/{file}\")\n",
    "    data = ds.variables[\"NDVI\"][:]\n",
    "    qa = ds.variables[\"QA\"][:]\n",
    "    if int(year) >= 2014:\n",
    "        is_cloudy = check_bit(qa, satellite=\"VIIRS\") #qa is integer -> bitwise operation to make a 16 bit binary value with 1 at 10th place and logical and operation between the two (10th bit is set to one when cloudy)\n",
    "    else:\n",
    "        is_cloudy = check_bit(qa, satellite=\"AVHRR\")\n",
    "    days = data.shape[0]\n",
    "    first_date = datetime(1981, 1, 1)\n",
    "    print(year)\n",
    "    for day in range(days):\n",
    "        date = (first_date + timedelta(days=int(ds.variables[\"time\"][day].data.item()))).strftime(\"%Y-%m-%d\")\n",
    "        cloud_masked = np.ma.masked_array(data[day], mask=~is_cloudy[day])\n",
    "        daily_flattened = cloud_masked.flatten()\n",
    "        daily_data = daily_flattened.filled(np.nan)\n",
    "        for _, dep in geo.iterrows():\n",
    "            if not np.all(np.isnan(daily_data)): #check if full array is not nan\n",
    "                prepared = prep(dep[\"geometry\"]) #use prep for batch operations\n",
    "                valid_points = []\n",
    "                valid_points.extend(filter(prepared.contains, points)) #find POINTS in dep\n",
    "                valid_indices = [points[point] for point in valid_points if point in points] #make a list of valid points that are in the dep\n",
    "                ndvi = daily_data[valid_indices]\n",
    "                mean_ndvi = np.nanmean(ndvi)\n",
    "            else:\n",
    "                mean_ndvi = np.nan\n",
    "            result.append({\"date\": date, \"departement\": dep[\"nom\"], \"dep\": dep[\"code\"], \"ndvi_mean\": float(mean_ndvi)})\n",
    "    df = pd.DataFrame(result)\n",
    "    df.to_csv(f\"{NDVI_DATA_URL}/no_cloud/{year}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single file (for concat last year)\n",
    "result = []\n",
    "year = \"2025\"\n",
    "ds = Dataset(f\"{NDVI_DATA_URL}/yearly_subsample/2025.nc\")\n",
    "data = ds.variables[\"NDVI\"][:]\n",
    "qa = ds.variables[\"QA\"][:]\n",
    "is_cloudy = check_bit(qa, satellite=\"VIIRS\") #qa is integer -> bitwise operation to make a 16 bit binary value with 1 at 10th place and logical and operation between the two (10th bit is set to one when cloudy)\n",
    "days = data.shape[0]\n",
    "first_date = datetime(1981, 1, 1)\n",
    "for day in range(days):\n",
    "    date = (first_date + timedelta(days=int(ds.variables[\"time\"][day].data.item()))).strftime(\"%Y-%m-%d\")\n",
    "    print(date)\n",
    "    cloud_masked = np.ma.masked_array(data[day], mask=~is_cloudy[day])\n",
    "    daily_flattened = cloud_masked.flatten()\n",
    "    daily_data = daily_flattened.filled(np.nan)\n",
    "    for _, dep in geo.iterrows():\n",
    "        if not np.all(np.isnan(daily_data)): #check if full array is not nan\n",
    "            prepared = prep(dep[\"geometry\"]) #use prep for batch operations\n",
    "            valid_points = []\n",
    "            valid_points.extend(filter(prepared.contains, points)) #find POINTS in dep\n",
    "            valid_indices = [points[point] for point in valid_points if point in points] #make a list of valid points that are in the dep\n",
    "            ndvi = daily_data[valid_indices]\n",
    "            mean_ndvi = np.nanmean(ndvi)\n",
    "        else:\n",
    "            mean_ndvi = np.nan\n",
    "        result.append({\"date\": date, \"departement\": dep[\"nom\"], \"dep\": dep[\"code\"], \"ndvi_mean\": float(mean_ndvi)})\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "hist = pd.read_csv(f\"{NDVI_DATA_URL}/no_cloud/{year}.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "hist = hist.sort_values(by=\"date\")\n",
    "\n",
    "current = df[df[\"date\"] > hist[\"date\"].iloc[-1]]\n",
    "\n",
    "result = pd.concat([hist, current])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>departement</th>\n",
       "      <th>dep</th>\n",
       "      <th>ndvi_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-06-24</td>\n",
       "      <td>Ain</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1981-06-24</td>\n",
       "      <td>Lozère</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1981-06-24</td>\n",
       "      <td>Allier</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1981-06-24</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1981-06-24</td>\n",
       "      <td>Hautes-Alpes</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13200</th>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>Essonne</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13201</th>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>Hauts-de-Seine</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13202</th>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>Seine-Saint-Denis</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13203</th>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>Val-de-Marne</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13204</th>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1520000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date              departement  dep  ndvi_mean\n",
       "0      1981-06-24                      Ain    1        NaN\n",
       "69     1981-06-24                   Lozère   48        NaN\n",
       "68     1981-06-24                   Allier    3        NaN\n",
       "67     1981-06-24  Alpes-de-Haute-Provence    4        NaN\n",
       "66     1981-06-24             Hautes-Alpes    5        NaN\n",
       "...           ...                      ...  ...        ...\n",
       "13200  2025-05-20                  Essonne   91        NaN\n",
       "13201  2025-05-20           Hauts-de-Seine   92        NaN\n",
       "13202  2025-05-20        Seine-Saint-Denis   93        NaN\n",
       "13203  2025-05-20             Val-de-Marne   94        NaN\n",
       "13204  2025-05-20               Val-d'Oise   95        NaN\n",
       "\n",
       "[1520000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(f\"{NDVI_DATA_URL}/no_cloud/{year}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
