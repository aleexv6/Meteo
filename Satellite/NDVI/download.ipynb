{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import os\n",
    "from config import NDVI_DATA_URL\n",
    "from netCDF4 import Dataset\n",
    "import io\n",
    "import xarray as xr\n",
    "import collections\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_files(year, files):\n",
    "    contents = []\n",
    "    exceptions = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        responses = await asyncio.gather(*(\n",
    "            session.get(f'https://www.ncei.noaa.gov/data/land-normalized-difference-vegetation-index/access/{year}/{file}')\n",
    "            for file in files\n",
    "            ), return_exceptions=True)\n",
    "    \n",
    "        for response in responses:\n",
    "            try: \n",
    "                contents.append(await response.read())\n",
    "            except:\n",
    "                exceptions.append(str(response.url))\n",
    "\n",
    "        return contents, exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptionsMap = collections.defaultdict(list) #hashmap to list every missed data from download\n",
    "for year in range(2004, datetime.today().year + 1):\n",
    "    print(year)\n",
    "    if not str(year) in os.listdir(NDVI_DATA_URL):\n",
    "        os.mkdir(f\"{NDVI_DATA_URL}/{year}\")\n",
    "    r = requests.get(f\"https://www.ncei.noaa.gov/data/land-normalized-difference-vegetation-index/access/{year}/\")\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    tds = soup.find_all(\"td\")\n",
    "    files = []\n",
    "    for td in tds:\n",
    "        if td.text[-3:] == \".nc\":\n",
    "            files.append(td.text)\n",
    "\n",
    "    #looks like we are limited in requests so we chunck them\n",
    "    total_files = len(files)\n",
    "    chunck = 18\n",
    "    n_times_chunck = total_files // chunck\n",
    "    \n",
    "    #loop through the array in 24-hour chunks\n",
    "    for n in range(n_times_chunck):\n",
    "        #calculate start and end indices for this day\n",
    "        start_idx = n * chunck       # 0, 18, 36, ...\n",
    "        end_idx = start_idx + chunck   # 18, 36, 54, ...\n",
    "\n",
    "        contents, exceptions = await get_files(year, files[start_idx:end_idx])\n",
    "\n",
    "        exceptionsMap[year].extend(exceptions)\n",
    "\n",
    "        datasets = [xr.open_dataset(io.BytesIO(content)) for content in contents]\n",
    "        for dataset in datasets:\n",
    "            subset = dataset.sel( #select subset for france only to save a lot a space \n",
    "                longitude=slice(-5, 10),\n",
    "                latitude=slice(51, 42))\n",
    "            subset.to_netcdf(f\"{NDVI_DATA_URL}/{year}/{subset.attrs[\"id\"]}\") #save new nc file\n",
    "    with open(f\"{NDVI_DATA_URL}/{year}/{year}Exceptions.json\", 'w') as json_file: #save exception file in case script break (internet loss...)\n",
    "        json.dump(dict(exceptionsMap), json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data that went to exceptions from async download\n",
    "#we go file by file because we drasticaly reduced the files to download\n",
    "with open(f\"{NDVI_DATA_URL}/Exceptions.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for year, files in data.items():\n",
    "    print(year)\n",
    "    for file in files:\n",
    "        file_req = requests.get(file)\n",
    "        file_req.raise_for_status()\n",
    "\n",
    "        dataset = xr.open_dataset(io.BytesIO(file_req.content))\n",
    "        subset = dataset.sel( #select subset for france only to save a lot a space \n",
    "                longitude=slice(-5, 10),\n",
    "                latitude=slice(51, 42))\n",
    "        subset.to_netcdf(f\"{NDVI_DATA_URL}/{year}/{subset.attrs[\"id\"]}\") #save new nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4.Variable'>\n",
       "int16 NDVI(time, latitude, longitude)\n",
       "    _FillValue: -9999\n",
       "    long_name: NOAA Climate Data Record of Normalized Difference Vegetation Index\n",
       "    units: 1\n",
       "    valid_range: [-1000 10000]\n",
       "    grid_mapping: crs\n",
       "    standard_name: normalized_difference_vegetation_index\n",
       "    add_offset: 0.0\n",
       "    scale_factor: 0.0001\n",
       "unlimited dimensions: \n",
       "current shape = (1, 180, 300)\n",
       "filling on"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset(f\"{NDVI_DATA_URL}/1981/AVHRR-Land_v005_AVH13C1_NOAA-07_19810711_c20170609200548.nc\").variables[\"NDVI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 190, 295)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset(f\"{NDVI_DATA_URL}/1981/out.nc\").variables[\"NDVI\"][:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
