{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import *\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_year(row): #make a market year row in datas\n",
    "    year = row['YEAR']\n",
    "    month = row['MONTH']\n",
    "    if month >= 9:\n",
    "        market_year = f\"{year}/{year + 1}\"\n",
    "    else:\n",
    "        market_year = f\"{year - 1}/{year}\"\n",
    "    return market_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "departements = { #set a dict of departement name as keys and dep code as value for missing dep values in datasets\n",
    "    'Ain': 1,\n",
    "    'Aisne': 2,\n",
    "    'Allier': 3,\n",
    "    'Alpes-de-Haute-Provence': 4,\n",
    "    'Hautes-Alpes': 5,\n",
    "    'Alpes-Maritimes': 6,\n",
    "    'Ardèche': 7,\n",
    "    'Ardennes': 8,\n",
    "    'Ariège': 9,\n",
    "    'Aube': 10,\n",
    "    'Aude': 11,\n",
    "    'Aveyron': 12,\n",
    "    'Bouches-du-Rhône': 13,\n",
    "    'Calvados': 14,\n",
    "    'Cantal': 15,\n",
    "    'Charente': 16,\n",
    "    'Charente-Maritime': 17,\n",
    "    'Cher': 18,\n",
    "    'Corrèze': 19,\n",
    "    'Corse': 20,\n",
    "    \"Côte-d'Or\": 21,\n",
    "    \"Côtes-d'Armor\": 22,\n",
    "    'Creuse': 23,\n",
    "    'Dordogne': 24,\n",
    "    'Doubs': 25,\n",
    "    'Drôme': 26,\n",
    "    'Eure': 27,\n",
    "    'Eure-et-Loir': 28,\n",
    "    'Finistère': 29,\n",
    "    'Gard': 30,\n",
    "    'Haute-Garonne': 31,\n",
    "    'Gers': 32,\n",
    "    'Gironde': 33,\n",
    "    'Hérault': 34,\n",
    "    'Ille-et-Vilaine': 35,\n",
    "    'Indre': 36,\n",
    "    'Indre-et-Loire': 37,\n",
    "    'Isère': 38,\n",
    "    'Jura': 39,\n",
    "    'Landes': 40,\n",
    "    'Loir-et-Cher': 41,\n",
    "    'Loire': 42,\n",
    "    'Haute-Loire': 43,\n",
    "    'Loire-Atlantique': 44,\n",
    "    'Loiret': 45,\n",
    "    'Lot': 46,\n",
    "    'Lot-et-Garonne': 47,\n",
    "    'Lozère': 48,\n",
    "    'Maine-et-Loire': 49,\n",
    "    'Manche': 50,\n",
    "    'Marne': 51,\n",
    "    'Haute-Marne': 52,\n",
    "    'Mayenne': 53,\n",
    "    'Meurthe-et-Moselle': 54,\n",
    "    'Meuse': 55,\n",
    "    'Morbihan': 56,\n",
    "    'Moselle': 57,\n",
    "    'Nièvre': 58,\n",
    "    'Nord': 59,\n",
    "    'Oise': 60,\n",
    "    'Orne': 61,\n",
    "    'Pas-de-Calais': 62,\n",
    "    'Puy-de-Dôme': 63,\n",
    "    'Pyrénées-Atlantiques': 64,\n",
    "    'Hautes-Pyrénées': 65,\n",
    "    'Pyrénées-Orientales': 66,\n",
    "    'Bas-Rhin': 67,\n",
    "    'Haut-Rhin': 68,\n",
    "    'Rhône': 69,\n",
    "    'Haute-Saône': 70,\n",
    "    'Saône-et-Loire': 71,\n",
    "    'Sarthe': 72,\n",
    "    'Savoie': 73,\n",
    "    'Haute-Savoie': 74,\n",
    "    'Paris': 75,\n",
    "    'Seine-Maritime': 76,\n",
    "    'Seine-et-Marne': 77,\n",
    "    'Yvelines': 78,\n",
    "    'Deux-Sèvres': 79,\n",
    "    'Somme': 80,\n",
    "    'Tarn': 81,\n",
    "    'Tarn-et-Garonne': 82,\n",
    "    'Var': 83,\n",
    "    'Vaucluse': 84,\n",
    "    'Vendée': 85,\n",
    "    'Vienne': 86,\n",
    "    'Haute-Vienne': 87,\n",
    "    'Vosges': 88,\n",
    "    'Yonne': 89,\n",
    "    'Territoire de Belfort': 90,\n",
    "    'Essonne': 91,\n",
    "    'Hauts-de-Seine': 92,\n",
    "    'Seine-Saint-Denis': 93,\n",
    "    'Val-de-Marne': 94,\n",
    "    \"Val-d'Oise\": 95\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : We will pivot data with month number in column name. Datas starts from 1 (Jan) to 12 (Dec), but it is understood and applicated that months from 9 to 12 are harvest year - 1 and months from 1 to 8 are harvest year.\n",
    "\n",
    "-> Market Year for EU wheat is September to Aug (for 2020 harvest, we plant in september 2019 and harvest july/aug 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[187], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m weather_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWEATHER_DATA_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/rr_tn_tx_tm-1950-2023.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#read raw weather data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m weather_raw_2024 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWEATHER_DATA_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/rr_tn_tx_tm-current.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#read raw weather data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m weather_raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYEAR-MONTH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(weather_raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_period(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#new column with YYYY-MM format\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m   1969\u001b[0m         new_col_dict,\n\u001b[0;32m   1970\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   1971\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   1972\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write(),\n\u001b[0;32m   1973\u001b[0m     )\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    153\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate, refs\u001b[38;5;241m=\u001b[39mrefs\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2139\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2122\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2123\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2135\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2138\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2139\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m _form_blocks(arrays, consolidate, refs)\n\u001b[0;32m   2140\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2212\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[0;32m   2209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m   2210\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m-> 2212\u001b[0m values, placement \u001b[38;5;241m=\u001b[39m _stack_arrays(\u001b[38;5;28mlist\u001b[39m(tup_block), dtype)\n\u001b[0;32m   2213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2214\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2254\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2252\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m-> 2254\u001b[0m     stacked[i] \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   2256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stacked, placement\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weather_raw = pd.read_csv(f\"{WEATHER_DATA_URL}/rr_tn_tx_tm-1950-2023.csv\").drop([\"Unnamed: 0\"], axis=1) #read raw weather data\n",
    "weather_raw_2024 = pd.read_csv(f\"{WEATHER_DATA_URL}/rr_tn_tx_tm-current.csv\").drop([\"Unnamed: 0\"], axis=1) #read raw weather data\n",
    "\n",
    "weather_raw[\"YEAR-MONTH\"] = pd.to_datetime(weather_raw[\"DATE\"]).dt.to_period('M') #new column with YYYY-MM format\n",
    "weatherMeanGroupedDepMonth = weather_raw[[\"YEAR-MONTH\", \"DEP\", \"RR\", \"TN\", \"TX\", \"TM\"]].groupby([\"YEAR-MONTH\", \"DEP\"]).mean() #group by year-month and dep then mean the values\n",
    "weather = weatherMeanGroupedDepMonth.reset_index() #remove multi indexing \n",
    "weather[\"YEAR\"] = weather[\"YEAR-MONTH\"].dt.year\n",
    "weather[\"MONTH\"] = weather[\"YEAR-MONTH\"].dt.month\n",
    "weather[\"MY\"] = weather.apply(get_market_year, axis=1) #add year, month and market year for merging \n",
    "\n",
    "weather_raw_2024 = pd.read_csv(f\"{WEATHER_DATA_URL}/rr_tn_tx_tm-current.csv\").drop([\"Unnamed: 0\"], axis=1) #read raw weather data\n",
    "weather_raw_2024 = weather_raw_2024[weather_raw_2024[\"DATE\"] < \"2024-09-01\"].reset_index(drop=True)\n",
    "weather_raw_2024[\"YEAR-MONTH\"] = pd.to_datetime(weather_raw_2024[\"DATE\"]).dt.to_period('M') #new column with YYYY-MM format\n",
    "weatherMeanGroupedDepMonth2024 = weather_raw_2024[[\"YEAR-MONTH\", \"DEP\", \"RR\", \"TN\", \"TX\", \"TM\"]].groupby([\"YEAR-MONTH\", \"DEP\"]).mean() #group by year-month and dep then mean the values\n",
    "weather2024 = weatherMeanGroupedDepMonth2024.reset_index() #remove multi indexing \n",
    "weather2024[\"YEAR\"] = weather2024[\"YEAR-MONTH\"].dt.year\n",
    "weather2024[\"MONTH\"] = weather2024[\"YEAR-MONTH\"].dt.month\n",
    "weather2024[\"MY\"] = weather2024.apply(get_market_year, axis=1) #add year, month and market year for merging \n",
    "\n",
    "weather = pd.concat([weather, weather2024])\n",
    "weather = weather[(weather[\"MY\"] >= \"1979/1980\") & (weather[\"MY\"] <= \"2023/2024\")] #-> final weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pivot = weather.pivot_table( # Pivot table for month datas as columns and not rows\n",
    "    index=['DEP', 'MY'],\n",
    "    columns='MONTH',\n",
    "    values=['RR', 'TN', 'TX', 'TM']\n",
    ")\n",
    "\n",
    "weather_pivot.columns = [ # rename columns with month number\n",
    "    f\"{col[0]}{col[1]}\" if isinstance(col, tuple) and col[1] != \"\" \n",
    "    else col for col in weather_pivot.columns\n",
    "]\n",
    "weather_pivot = weather_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yields data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st dataset (1900 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields_raw = pd.read_csv(f\"{YIELDS_DATA_URL}/2021-001_Schauberger-et-al_Data_FILTERED/wheat_total_data_1900-2018_FILTERED.txt\", sep=';')\n",
    "\n",
    "#aggregate Corse du sud and Haute Corse into one Corse department :\n",
    "corseSud = yields_raw[yields_raw['department'] == \"Corse-du-sud\"].fillna(0)\n",
    "corseHaute = yields_raw[yields_raw['department'] == \"Haute-Corse\"].fillna(0)\n",
    "corseArea = corseSud[\"area\"].reset_index(drop=True) + corseHaute[\"area\"].reset_index(drop=True)\n",
    "corseProd = corseSud[\"production\"].reset_index(drop=True) + corseHaute[\"production\"].reset_index(drop=True)\n",
    "corseYield = (corseSud[\"production\"].reset_index(drop=True) + corseHaute[\"production\"].reset_index(drop=True)) / (corseSud[\"area\"].reset_index(drop=True) + corseHaute[\"area\"].reset_index(drop=True))\n",
    "corseYears = pd.Series(range(1900, 2019))\n",
    "corse = pd.DataFrame({\"department\": \"Corse\", \"year\": corseYears, \"yield\": corseYield, \"area\": corseArea, \"production\": corseProd})\n",
    "yields_raw = pd.concat([yields_raw, corse])\n",
    "yields_raw = yields_raw[(yields_raw['department'] != \"Corse-du-sud\") & (yields_raw['department'] != \"Haute-Corse\")]\n",
    "\n",
    "yields_raw['DEP'] = yields_raw['department'].map(departements).replace('NA', np.nan) #map dep name to dep code\n",
    "yields_raw = yields_raw.drop(\"department\", axis=1)\n",
    "yields_raw[\"MY\"] = (yields_raw['year'] - 1).astype(str) + '/' + yields_raw['year'].astype(str) \n",
    "oldYields = yields_raw[yields_raw[\"year\"] > 1979] #-> final yields data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd dataset (2000 - 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\AppData\\Local\\Temp\\ipykernel_16232\\1724735824.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  yields[\"MY\"] = (yields['ANNEE'] - 1).astype(str) + '/' + yields['ANNEE'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "yields_raw = pd.read_csv(f\"{YIELDS_DATA_URL}/SCR-GRC-hist_dep_surface_prod_cult_cer-A25.csv\", encoding='utf-8')\n",
    "yields_raw[\"ESPECES\"] = yields_raw[\"ESPECES\"].str.strip() #remove left and white spaces\n",
    "yields_raw = yields_raw[yields_raw[\"ESPECES\"] == \"Blé tendre\"].reset_index(drop=True) #filter soft wheat\n",
    "\n",
    "#Corse\n",
    "corseSud = yields_raw[yields_raw[\"DEP\"] == \"2A\"]\n",
    "corseSud = pd.concat([pd.DataFrame({'ANNEE': list(range(2000, 2016))}), corseSud], ignore_index=True).fillna(0)\n",
    "corseHaute = yields_raw[yields_raw['DEP'] == \"2B\"].fillna(0)\n",
    "corseArea = corseSud[\"CULT_SURF\"].reset_index(drop=True) + corseHaute[\"CULT_SURF\"].reset_index(drop=True)\n",
    "corseProd = corseSud[\"CULT_PROD\"].reset_index(drop=True) + corseHaute[\"CULT_PROD\"].reset_index(drop=True)\n",
    "corseYield = (corseSud[\"CULT_PROD\"].reset_index(drop=True) + corseHaute[\"CULT_PROD\"].reset_index(drop=True)) / (corseSud[\"CULT_SURF\"].reset_index(drop=True) + corseHaute[\"CULT_SURF\"].reset_index(drop=True))\n",
    "corseYears = pd.Series(range(2000, 2026))\n",
    "corse = pd.DataFrame({\"DEPARTEMENT\": \"Corse\", \"DEP\": 20, \"ANNEE\": corseYears, \"CULT_REND\": corseYield, \"CULT_SURF\": corseArea, \"CULT_PROD\": corseProd})\n",
    "yields_raw = pd.concat([yields_raw, corse])\n",
    "yields_raw = yields_raw[(yields_raw['DEP'] != \"2A\") & (yields_raw['DEP'] != \"2B\")]\n",
    "\n",
    "yields_raw[\"DEP\"] = yields_raw[\"DEP\"].astype(int)\n",
    "yields = yields_raw[[\"ANNEE\", \"DEP\", \"CULT_SURF\", \"CULT_REND\", \"CULT_PROD\"]] #keep only wanted data\n",
    "yields[\"MY\"] = (yields['ANNEE'] - 1).astype(str) + '/' + yields['ANNEE'].astype(str) \n",
    "yields = yields.rename(columns={\"ANNEE\": \"year\", \"CULT_SURF\": \"area\", \"CULT_REND\": \"yield\", \"CULT_PROD\": \"production\"})\n",
    "yields['yield'] = yields['yield'] / 10 #convert to kg/ha\n",
    "newYields = yields[yields[\"year\"] <= 2024] #-> final yield data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat both yields datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>area</th>\n",
       "      <th>production</th>\n",
       "      <th>DEP</th>\n",
       "      <th>MY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980</td>\n",
       "      <td>4.39805</td>\n",
       "      <td>36001.0</td>\n",
       "      <td>158334.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1979/1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981</td>\n",
       "      <td>4.30319</td>\n",
       "      <td>36075.0</td>\n",
       "      <td>155237.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1980/1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1982</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>38050.0</td>\n",
       "      <td>190250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1981/1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>3.29500</td>\n",
       "      <td>37924.0</td>\n",
       "      <td>124959.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1982/1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984</td>\n",
       "      <td>5.90000</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>236000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1983/1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2019/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>643.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2020/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>539.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2021/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2022/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>2024</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2023/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4032 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year    yield     area  production  DEP         MY\n",
       "0     1980  4.39805  36001.0    158334.3    1  1979/1980\n",
       "1     1981  4.30319  36075.0    155237.5    1  1980/1981\n",
       "2     1982  5.00000  38050.0    190250.0    1  1981/1982\n",
       "3     1983  3.29500  37924.0    124959.6    1  1982/1983\n",
       "4     1984  5.90000  40000.0    236000.0    1  1983/1984\n",
       "...    ...      ...      ...         ...  ...        ...\n",
       "4027  2020  0.35000     72.0       252.0   20  2019/2020\n",
       "4028  2021  0.65000     99.0       643.5   20  2020/2021\n",
       "4029  2022  0.65000     83.0       539.5   20  2021/2022\n",
       "4030  2023  0.40000     63.0       252.0   20  2022/2023\n",
       "4031  2024  0.40000     63.0       252.0   20  2023/2024\n",
       "\n",
       "[4032 rows x 6 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newYields = newYields[newYields['year'] >= 2019]\n",
    "yields = pd.concat([oldYields, newYields])\n",
    "yields = yields.dropna().reset_index(drop=True)\n",
    "yields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vapor pressure deficit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\AppData\\Local\\Temp\\ipykernel_16232\\3789123208.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  vpd_raw = pd.concat([vpd_raw, vpd_dep]) #concat data\n"
     ]
    }
   ],
   "source": [
    "vpd_raw = pd.DataFrame(columns=[\"dep\", \"date\", \"vpd_max\", \"vpd_min\", \"vpd_mean\"])\n",
    "for vpd_file in os.listdir(f\"{VPD_DATA_URL}/dailyDepDatas/\"): #loop throught files\n",
    "    vpd_dep = pd.read_json(f\"{VPD_DATA_URL}/dailyDepDatas/{vpd_file}\") #read json\n",
    "    vpd_raw = pd.concat([vpd_raw, vpd_dep]) #concat data\n",
    "vpd_raw['DEP'] = vpd_raw['dep'].map(departements) #map dep name to dep code\n",
    "vpd_raw[\"YEAR-MONTH\"] = pd.to_datetime(vpd_raw[\"date\"]).dt.to_period('M') #new column with YYYY-MM format\n",
    "vpdMeanGroupedDepMonth = vpd_raw[[\"vpd_max\", \"vpd_min\", \"vpd_mean\", \"YEAR-MONTH\", \"DEP\"]].groupby([\"YEAR-MONTH\", \"DEP\"]).mean() #group by year-month and dep then mean the values\n",
    "vpd = vpdMeanGroupedDepMonth.reset_index() #remove multi indexing \n",
    "vpd = vpd.dropna() #removes nan values (when nan value, there is no data for the dep)\n",
    "vpd[\"YEAR\"] = vpd[\"YEAR-MONTH\"].dt.year\n",
    "vpd[\"MONTH\"] = vpd[\"YEAR-MONTH\"].dt.month\n",
    "vpd[\"MY\"] = vpd.apply(get_market_year, axis=1) #add year, month and market year for merging \n",
    "vpd = vpd[vpd[\"MY\"] >= \"1979/1980\"] #-> final vpd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Historical calculation with weather data\n",
    "vpd_raw = pd.read_csv(f\"{VPD_DATA_URL}/vpd_historical_1950_2024.csv\")\n",
    "vpd_raw[\"YEAR-MONTH\"] = pd.to_datetime(vpd_raw[\"YEAR-MONTH\"]).dt.to_period('M') #new column with YYYY-MM format\n",
    "vpdMeanGroupedDepMonth = vpd_raw[[\"vpd_max\", \"vpd_min\", \"vpd_mean\", \"YEAR-MONTH\", \"DEP\"]].groupby([\"YEAR-MONTH\", \"DEP\"]).mean() #group by year-month and dep then mean the values\n",
    "vpd = vpdMeanGroupedDepMonth.reset_index() #remove multi indexing \n",
    "vpd = vpd.dropna() #removes nan values (when nan value, there is no data for the dep)\n",
    "vpd[\"YEAR\"] = vpd[\"YEAR-MONTH\"].dt.year\n",
    "vpd[\"MONTH\"] = vpd[\"YEAR-MONTH\"].dt.month\n",
    "vpd[\"MY\"] = vpd.apply(get_market_year, axis=1) #add year, month and market year for merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpd_pivot = vpd.pivot_table( # pivot table for month datas as columns and not rows\n",
    "    index=['DEP', 'MY'],\n",
    "    columns='MONTH',\n",
    "    values=['vpd_mean', 'vpd_min', 'vpd_max']\n",
    ")\n",
    "\n",
    "vpd_pivot.columns = [ # rename columns with month number\n",
    "    f\"{col[0]}{col[1]}\" if isinstance(col, tuple) and col[1] != \"\" \n",
    "    else col for col in vpd_pivot.columns\n",
    "]\n",
    "vpd_pivot = vpd_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhanced Vegetation Index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\AppData\\Local\\Temp\\ipykernel_16232\\33089076.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  evi = pd.concat([evi, evi_dep]) #concat data\n"
     ]
    }
   ],
   "source": [
    "evi = pd.DataFrame(columns=[\"name\", \"code\", \"date\", \"mean_data\"]) \n",
    "for evi_file in os.listdir(f\"{EVI_DATA_URL}/monthlyDepMean/\"): #loop throught files\n",
    "    evi_dep = pd.read_json(f\"{EVI_DATA_URL}/monthlyDepMean/{evi_file}\") #read json\n",
    "    evi = pd.concat([evi, evi_dep]) #concat data\n",
    "evi[\"YEAR-MONTH\"] = pd.to_datetime(evi[\"date\"]).dt.to_period('M') #set period (already to monthly data but we keep same format for every dataset (Year-Month))\n",
    "evi = evi.rename(columns={\"code\": \"DEP\", \"mean_data\": \"evi\"}) #rename for same format\n",
    "evi = evi[[\"YEAR-MONTH\", \"DEP\", \"evi\"]].sort_values(by=\"YEAR-MONTH\") #keep wanted data \n",
    "evi[\"YEAR\"] = evi[\"YEAR-MONTH\"].dt.year\n",
    "evi[\"MONTH\"] = evi[\"YEAR-MONTH\"].dt.month\n",
    "evi[\"MY\"] = evi.apply(get_market_year, axis=1) #add year, month and market year for merging \n",
    "evi = evi[evi[\"MY\"] >= \"2000/2001\"] #-> final evi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "evi_pivot = evi.pivot_table( # pivot table for month datas as columns and not rows\n",
    "    index=['DEP', 'MY'],\n",
    "    columns='MONTH',\n",
    "    values=['evi']\n",
    ")\n",
    "\n",
    "evi_pivot.columns = [ # rename columns with month number\n",
    "    f\"{col[0]}{col[1]}\" if isinstance(col, tuple) and col[1] != \"\" \n",
    "    else col for col in evi_pivot.columns\n",
    "]\n",
    "evi_pivot = evi_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soil Organic Matter data (Particulate organic matter (POM) and Mineral-associated organic matter (MAOM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_pom = pd.read_json(f\"{SOM_DATA_URL}/pom.json\") #read json\n",
    "som_pom['DEP'] = som_pom['nom'].map(departements) #map dep name to dep codevpd['DEP'] = vpd['dep'].map(departements) #map dep name to dep code\n",
    "som_pom = som_pom.drop(\"nom\", axis=1) #remove unwanted dep name -> final som pom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "maom_pom = pd.read_json(f\"{SOM_DATA_URL}/maom.json\") #read json\n",
    "maom_pom['DEP'] = maom_pom['nom'].map(departements) #map dep name to dep codevpd['DEP'] = vpd['dep'].map(departements) #map dep name to dep code\n",
    "maom_pom = maom_pom.drop(\"nom\", axis=1) #remove unwanted dep name -> final som maom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "awc = pd.read_json(f\"{AWC_DATA_URL}/AWC.json\") #read json\n",
    "awc['DEP'] = awc['nom'].map(departements) #map dep name to dep codevpd['DEP'] = vpd['dep'].map(departements) #map dep name to dep code\n",
    "awc = awc.drop(\"nom\", axis=1) #remove unwanted dep name -> final AWC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = yields.merge(weather_pivot, on=['DEP', 'MY'], how='left')\n",
    "result = result.merge(vpd_pivot, on=['DEP', 'MY'], how='left')\n",
    "result = result.merge(evi_pivot, on=['DEP', 'MY'], how='left')\n",
    "\n",
    "result = result.merge(som_pom, on=\"DEP\", how=\"left\")\n",
    "result = result.merge(maom_pom, on=\"DEP\", how=\"left\")\n",
    "result = result.merge(awc, on=\"DEP\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.dropna(subset=['yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>area</th>\n",
       "      <th>production</th>\n",
       "      <th>DEP</th>\n",
       "      <th>MY</th>\n",
       "      <th>RR1</th>\n",
       "      <th>RR2</th>\n",
       "      <th>RR3</th>\n",
       "      <th>RR4</th>\n",
       "      <th>...</th>\n",
       "      <th>evi6</th>\n",
       "      <th>evi7</th>\n",
       "      <th>evi8</th>\n",
       "      <th>evi9</th>\n",
       "      <th>evi10</th>\n",
       "      <th>evi11</th>\n",
       "      <th>evi12</th>\n",
       "      <th>pom</th>\n",
       "      <th>maom</th>\n",
       "      <th>awc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980</td>\n",
       "      <td>4.39805</td>\n",
       "      <td>36001.0</td>\n",
       "      <td>158334.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1979/1980</td>\n",
       "      <td>3.672457</td>\n",
       "      <td>3.484615</td>\n",
       "      <td>4.661456</td>\n",
       "      <td>1.224872</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.789692</td>\n",
       "      <td>26.925089</td>\n",
       "      <td>0.107088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981</td>\n",
       "      <td>4.30319</td>\n",
       "      <td>36075.0</td>\n",
       "      <td>155237.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1980/1981</td>\n",
       "      <td>5.279117</td>\n",
       "      <td>2.298026</td>\n",
       "      <td>4.151613</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.789692</td>\n",
       "      <td>26.925089</td>\n",
       "      <td>0.107088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1982</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>38050.0</td>\n",
       "      <td>190250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1981/1982</td>\n",
       "      <td>3.686452</td>\n",
       "      <td>0.559464</td>\n",
       "      <td>3.402339</td>\n",
       "      <td>0.685812</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.789692</td>\n",
       "      <td>26.925089</td>\n",
       "      <td>0.107088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>3.29500</td>\n",
       "      <td>37924.0</td>\n",
       "      <td>124959.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1982/1983</td>\n",
       "      <td>3.015110</td>\n",
       "      <td>3.857753</td>\n",
       "      <td>3.601241</td>\n",
       "      <td>8.489750</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.789692</td>\n",
       "      <td>26.925089</td>\n",
       "      <td>0.107088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984</td>\n",
       "      <td>5.90000</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>236000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1983/1984</td>\n",
       "      <td>5.722266</td>\n",
       "      <td>3.942845</td>\n",
       "      <td>3.163952</td>\n",
       "      <td>1.107667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.789692</td>\n",
       "      <td>26.925089</td>\n",
       "      <td>0.107088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2019/2020</td>\n",
       "      <td>1.687465</td>\n",
       "      <td>0.514343</td>\n",
       "      <td>2.962535</td>\n",
       "      <td>3.276762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.431090</td>\n",
       "      <td>0.388402</td>\n",
       "      <td>0.355846</td>\n",
       "      <td>0.336295</td>\n",
       "      <td>0.313358</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>643.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2020/2021</td>\n",
       "      <td>5.630784</td>\n",
       "      <td>2.620412</td>\n",
       "      <td>1.022414</td>\n",
       "      <td>1.969150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405275</td>\n",
       "      <td>0.392680</td>\n",
       "      <td>0.360204</td>\n",
       "      <td>0.371781</td>\n",
       "      <td>0.375880</td>\n",
       "      <td>0.340750</td>\n",
       "      <td>0.330526</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>539.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2021/2022</td>\n",
       "      <td>0.921650</td>\n",
       "      <td>0.828915</td>\n",
       "      <td>1.524876</td>\n",
       "      <td>3.056282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403204</td>\n",
       "      <td>0.379189</td>\n",
       "      <td>0.366802</td>\n",
       "      <td>0.343552</td>\n",
       "      <td>0.334657</td>\n",
       "      <td>0.288043</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>4.384367</td>\n",
       "      <td>2.767651</td>\n",
       "      <td>1.613400</td>\n",
       "      <td>1.570661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417501</td>\n",
       "      <td>0.382688</td>\n",
       "      <td>0.369777</td>\n",
       "      <td>0.350959</td>\n",
       "      <td>0.324504</td>\n",
       "      <td>0.316170</td>\n",
       "      <td>0.319895</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>2024</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2023/2024</td>\n",
       "      <td>1.743833</td>\n",
       "      <td>4.482218</td>\n",
       "      <td>3.718722</td>\n",
       "      <td>1.410719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402786</td>\n",
       "      <td>0.380648</td>\n",
       "      <td>0.358753</td>\n",
       "      <td>0.355716</td>\n",
       "      <td>0.354408</td>\n",
       "      <td>0.332111</td>\n",
       "      <td>0.312834</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4032 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year    yield     area  production  DEP         MY       RR1       RR2  \\\n",
       "0     1980  4.39805  36001.0    158334.3    1  1979/1980  3.672457  3.484615   \n",
       "1     1981  4.30319  36075.0    155237.5    1  1980/1981  5.279117  2.298026   \n",
       "2     1982  5.00000  38050.0    190250.0    1  1981/1982  3.686452  0.559464   \n",
       "3     1983  3.29500  37924.0    124959.6    1  1982/1983  3.015110  3.857753   \n",
       "4     1984  5.90000  40000.0    236000.0    1  1983/1984  5.722266  3.942845   \n",
       "...    ...      ...      ...         ...  ...        ...       ...       ...   \n",
       "4027  2020  0.35000     72.0       252.0   20  2019/2020  1.687465  0.514343   \n",
       "4028  2021  0.65000     99.0       643.5   20  2020/2021  5.630784  2.620412   \n",
       "4029  2022  0.65000     83.0       539.5   20  2021/2022  0.921650  0.828915   \n",
       "4030  2023  0.40000     63.0       252.0   20  2022/2023  4.384367  2.767651   \n",
       "4031  2024  0.40000     63.0       252.0   20  2023/2024  1.743833  4.482218   \n",
       "\n",
       "           RR3       RR4  ...      evi6      evi7      evi8      evi9  \\\n",
       "0     4.661456  1.224872  ...       NaN       NaN       NaN       NaN   \n",
       "1     4.151613  0.824649  ...       NaN       NaN       NaN       NaN   \n",
       "2     3.402339  0.685812  ...       NaN       NaN       NaN       NaN   \n",
       "3     3.601241  8.489750  ...       NaN       NaN       NaN       NaN   \n",
       "4     3.163952  1.107667  ...       NaN       NaN       NaN       NaN   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "4027  2.962535  3.276762  ...  0.435666  0.431090  0.388402  0.355846   \n",
       "4028  1.022414  1.969150  ...  0.405275  0.392680  0.360204  0.371781   \n",
       "4029  1.524876  3.056282  ...  0.403204  0.379189  0.366802  0.343552   \n",
       "4030  1.613400  1.570661  ...  0.417501  0.382688  0.369777  0.350959   \n",
       "4031  3.718722  1.410719  ...  0.402786  0.380648  0.358753  0.355716   \n",
       "\n",
       "         evi10     evi11     evi12        pom       maom       awc  \n",
       "0          NaN       NaN       NaN  16.789692  26.925089  0.107088  \n",
       "1          NaN       NaN       NaN  16.789692  26.925089  0.107088  \n",
       "2          NaN       NaN       NaN  16.789692  26.925089  0.107088  \n",
       "3          NaN       NaN       NaN  16.789692  26.925089  0.107088  \n",
       "4          NaN       NaN       NaN  16.789692  26.925089  0.107088  \n",
       "...        ...       ...       ...        ...        ...       ...  \n",
       "4027  0.336295  0.313358  0.300604  15.657990  28.322897  0.109897  \n",
       "4028  0.375880  0.340750  0.330526  15.657990  28.322897  0.109897  \n",
       "4029  0.334657  0.288043  0.291791  15.657990  28.322897  0.109897  \n",
       "4030  0.324504  0.316170  0.319895  15.657990  28.322897  0.109897  \n",
       "4031  0.354408  0.332111  0.312834  15.657990  28.322897  0.109897  \n",
       "\n",
       "[4032 rows x 105 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"wheat_model_dataset_1980_2024.csv\", index=False) #dataset to csv ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
