{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import *\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_year(row): #make a market year row in datas\n",
    "    year = row['YEAR']\n",
    "    month = row['MONTH']\n",
    "    if month >= 9:\n",
    "        market_year = f\"{year}/{year + 1}\"\n",
    "    else:\n",
    "        market_year = f\"{year - 1}/{year}\"\n",
    "    return market_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "departements = { #set a dict of departement name as keys and dep code as value for missing dep values in datasets\n",
    "    'Ain': 1,\n",
    "    'Aisne': 2,\n",
    "    'Allier': 3,\n",
    "    'Alpes-de-Haute-Provence': 4,\n",
    "    'Hautes-Alpes': 5,\n",
    "    'Alpes-Maritimes': 6,\n",
    "    'Ardèche': 7,\n",
    "    'Ardennes': 8,\n",
    "    'Ariège': 9,\n",
    "    'Aube': 10,\n",
    "    'Aude': 11,\n",
    "    'Aveyron': 12,\n",
    "    'Bouches-du-Rhône': 13,\n",
    "    'Calvados': 14,\n",
    "    'Cantal': 15,\n",
    "    'Charente': 16,\n",
    "    'Charente-Maritime': 17,\n",
    "    'Cher': 18,\n",
    "    'Corrèze': 19,\n",
    "    'Corse': 20,\n",
    "    \"Côte-d'Or\": 21,\n",
    "    \"Côtes-d'Armor\": 22,\n",
    "    'Creuse': 23,\n",
    "    'Dordogne': 24,\n",
    "    'Doubs': 25,\n",
    "    'Drôme': 26,\n",
    "    'Eure': 27,\n",
    "    'Eure-et-Loir': 28,\n",
    "    'Finistère': 29,\n",
    "    'Gard': 30,\n",
    "    'Haute-Garonne': 31,\n",
    "    'Gers': 32,\n",
    "    'Gironde': 33,\n",
    "    'Hérault': 34,\n",
    "    'Ille-et-Vilaine': 35,\n",
    "    'Indre': 36,\n",
    "    'Indre-et-Loire': 37,\n",
    "    'Isère': 38,\n",
    "    'Jura': 39,\n",
    "    'Landes': 40,\n",
    "    'Loir-et-Cher': 41,\n",
    "    'Loire': 42,\n",
    "    'Haute-Loire': 43,\n",
    "    'Loire-Atlantique': 44,\n",
    "    'Loiret': 45,\n",
    "    'Lot': 46,\n",
    "    'Lot-et-Garonne': 47,\n",
    "    'Lozère': 48,\n",
    "    'Maine-et-Loire': 49,\n",
    "    'Manche': 50,\n",
    "    'Marne': 51,\n",
    "    'Haute-Marne': 52,\n",
    "    'Mayenne': 53,\n",
    "    'Meurthe-et-Moselle': 54,\n",
    "    'Meuse': 55,\n",
    "    'Morbihan': 56,\n",
    "    'Moselle': 57,\n",
    "    'Nièvre': 58,\n",
    "    'Nord': 59,\n",
    "    'Oise': 60,\n",
    "    'Orne': 61,\n",
    "    'Pas-de-Calais': 62,\n",
    "    'Puy-de-Dôme': 63,\n",
    "    'Pyrénées-Atlantiques': 64,\n",
    "    'Hautes-Pyrénées': 65,\n",
    "    'Pyrénées-Orientales': 66,\n",
    "    'Bas-Rhin': 67,\n",
    "    'Haut-Rhin': 68,\n",
    "    'Rhône': 69,\n",
    "    'Haute-Saône': 70,\n",
    "    'Saône-et-Loire': 71,\n",
    "    'Sarthe': 72,\n",
    "    'Savoie': 73,\n",
    "    'Haute-Savoie': 74,\n",
    "    'Paris': 75,\n",
    "    'Seine-Maritime': 76,\n",
    "    'Seine-et-Marne': 77,\n",
    "    'Yvelines': 78,\n",
    "    'Deux-Sèvres': 79,\n",
    "    'Somme': 80,\n",
    "    'Tarn': 81,\n",
    "    'Tarn-et-Garonne': 82,\n",
    "    'Var': 83,\n",
    "    'Vaucluse': 84,\n",
    "    'Vendée': 85,\n",
    "    'Vienne': 86,\n",
    "    'Haute-Vienne': 87,\n",
    "    'Vosges': 88,\n",
    "    'Yonne': 89,\n",
    "    'Territoire de Belfort': 90,\n",
    "    'Essonne': 91,\n",
    "    'Hauts-de-Seine': 92,\n",
    "    'Seine-Saint-Denis': 93,\n",
    "    'Val-de-Marne': 94,\n",
    "    \"Val-d'Oise\": 95\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : We will pivot data with month number in column name. Datas starts from 1 (Jan) to 12 (Dec), but it is understood and applicated that months from 9 to 12 are harvest year - 1 and months from 1 to 8 are harvest year.\n",
    "\n",
    "-> Market Year for EU wheat is September to Aug (for 2020 harvest, we plant in september 2019 and harvest july/aug 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m weather_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWEATHER_DATA_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/rr_tn_tx_tm-1950-2023.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#read raw weather data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m weather_raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYEAR-MONTH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(weather_raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_period(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#new column with YYYY-MM format\u001b[39;00m\n\u001b[0;32m      3\u001b[0m weatherMeanGroupedDepMonth \u001b[38;5;241m=\u001b[39m weather_raw[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYEAR-MONTH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTM\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYEAR-MONTH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEP\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;66;03m#group by year-month and dep then mean the values\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\alexl\\miniconda3\\envs\\conda-env\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weather_raw = pd.read_csv(f\"{WEATHER_DATA_URL}/rr_tn_tx_tm-1950-2023.csv\").drop([\"Unnamed: 0\"], axis=1) #read raw weather data\n",
    "weather_raw[\"YEAR-MONTH\"] = pd.to_datetime(weather_raw[\"DATE\"]).dt.to_period('M') #new column with YYYY-MM format\n",
    "weatherMeanGroupedDepMonth = weather_raw[[\"YEAR-MONTH\", \"DEP\", \"RR\", \"TN\", \"TX\", \"TM\"]].groupby([\"YEAR-MONTH\", \"DEP\"]).mean() #group by year-month and dep then mean the values\n",
    "weather = weatherMeanGroupedDepMonth.reset_index() #remove multi indexing \n",
    "weather[\"YEAR\"] = weather[\"YEAR-MONTH\"].dt.year\n",
    "weather[\"MONTH\"] = weather[\"YEAR-MONTH\"].dt.month\n",
    "weather[\"MY\"] = weather.apply(get_market_year, axis=1) #add year, month and market year for merging \n",
    "weather = weather[(weather[\"MY\"] >= \"1979/1980\") & (weather[\"MY\"] <= \"2022/2023\")] #-> final weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pivot = weather.pivot_table( # Pivot table for month datas as columns and not rows\n",
    "    index=['DEP', 'MY'],\n",
    "    columns='MONTH',\n",
    "    values=['RR', 'TN', 'TX', 'TM']\n",
    ")\n",
    "\n",
    "weather_pivot.columns = [ # rename columns with month number\n",
    "    f\"{col[0]}{col[1]}\" if isinstance(col, tuple) and col[1] != \"\" \n",
    "    else col for col in weather_pivot.columns\n",
    "]\n",
    "weather_pivot = weather_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yields data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st dataset (1900 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields_raw = pd.read_csv(f\"{YIELDS_DATA_URL}/2021-001_Schauberger-et-al_Data_FILTERED/wheat_total_data_1900-2018_FILTERED.txt\", sep=';')\n",
    "\n",
    "#aggregate Corse du sud and Haute Corse into one Corse department :\n",
    "corseSud = yields_raw[yields_raw['department'] == \"Corse-du-sud\"].fillna(0)\n",
    "corseHaute = yields_raw[yields_raw['department'] == \"Haute-Corse\"].fillna(0)\n",
    "corseArea = corseSud[\"area\"].reset_index(drop=True) + corseHaute[\"area\"].reset_index(drop=True)\n",
    "corseProd = corseSud[\"production\"].reset_index(drop=True) + corseHaute[\"production\"].reset_index(drop=True)\n",
    "corseYield = corseSud[\"yield\"].reset_index(drop=True) + corseHaute[\"yield\"].reset_index(drop=True)\n",
    "corseYears = pd.Series(range(1900, 2019))\n",
    "corse = pd.DataFrame({\"department\": \"Corse\", \"year\": corseYears, \"yield\": corseYield, \"area\": corseArea, \"production\": corseProd})\n",
    "yields_raw = pd.concat([yields_raw, corse])\n",
    "yields_raw = yields_raw[(yields_raw['department'] != \"Corse-du-sud\") & (yields_raw['department'] != \"Haute-Corse\")]\n",
    "\n",
    "yields_raw['dep'] = yields_raw['department'].map(departements).replace('NA', np.nan) #map dep name to dep code\n",
    "yields_raw[\"MY\"] = (yields_raw['year'] - 1).astype(str) + '/' + yields_raw['year'].astype(str) \n",
    "yields_raw = yields_raw.rename(columns={\"dep\": \"DEP\"})\n",
    "yields = yields_raw[yields_raw[\"year\"] > 1979] #-> final yields data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd dataset (2000 - 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\AppData\\Local\\Temp\\ipykernel_1364\\2663592425.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  yields[\"MY\"] = (yields['ANNEE'] - 1).astype(str) + '/' + yields['ANNEE'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "yields_raw = pd.read_csv(f\"{YIELDS_DATA_URL}/SCR-GRC-hist_dep_surface_prod_cult_cer-A25.csv\", sep=';', encoding='latin1')\n",
    "yields_raw[\"ESPECES\"] = yields_raw[\"ESPECES\"].str.strip() #remove left and white spaces\n",
    "yields_raw = yields_raw[yields_raw[\"ESPECES\"] == \"Blé tendre\"].reset_index(drop=True) #filter soft wheat\n",
    "yields_raw[\"DEP\"] = yields_raw[\"DEP\"].str.strip().replace({\"2A\": \"20\", \"2B\": \"20\"}) #strip white spaces an replace string values to dep number\n",
    "yields_raw[\"DEP\"] = yields_raw[\"DEP\"].astype(int)\n",
    "yields = yields_raw[[\"ANNEE\", \"DEP\", \"CULT_SURF\", \"CULT_REND\"]] #keep only wanted data\n",
    "yields[\"MY\"] = (yields['ANNEE'] - 1).astype(str) + '/' + yields['ANNEE'].astype(str) \n",
    "yields = yields[(yields[\"ANNEE\"] >= 2001) & (yields[\"ANNEE\"] < 2024)] #-> final weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANNEE</th>\n",
       "      <th>DEP</th>\n",
       "      <th>CULT_SURF</th>\n",
       "      <th>CULT_REND</th>\n",
       "      <th>MY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>77</td>\n",
       "      <td>134939,00</td>\n",
       "      <td>75,00</td>\n",
       "      <td>2000/2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>77</td>\n",
       "      <td>139375,00</td>\n",
       "      <td>85,00</td>\n",
       "      <td>2001/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>77</td>\n",
       "      <td>137375,00</td>\n",
       "      <td>68,98</td>\n",
       "      <td>2002/2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>77</td>\n",
       "      <td>141446,00</td>\n",
       "      <td>90,00</td>\n",
       "      <td>2003/2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005</td>\n",
       "      <td>77</td>\n",
       "      <td>143677,00</td>\n",
       "      <td>80,00</td>\n",
       "      <td>2004/2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>2019</td>\n",
       "      <td>20</td>\n",
       "      <td>96,00</td>\n",
       "      <td>40,00</td>\n",
       "      <td>2018/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>2020</td>\n",
       "      <td>20</td>\n",
       "      <td>70,00</td>\n",
       "      <td>35,00</td>\n",
       "      <td>2019/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>2021</td>\n",
       "      <td>20</td>\n",
       "      <td>97,00</td>\n",
       "      <td>65,00</td>\n",
       "      <td>2020/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>2022</td>\n",
       "      <td>20</td>\n",
       "      <td>80,00</td>\n",
       "      <td>65,00</td>\n",
       "      <td>2021/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>2023</td>\n",
       "      <td>20</td>\n",
       "      <td>60,00</td>\n",
       "      <td>40,00</td>\n",
       "      <td>2022/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ANNEE  DEP  CULT_SURF CULT_REND         MY\n",
       "1      2001   77  134939,00     75,00  2000/2001\n",
       "2      2002   77  139375,00     85,00  2001/2002\n",
       "3      2003   77  137375,00     68,98  2002/2003\n",
       "4      2004   77  141446,00     90,00  2003/2004\n",
       "5      2005   77  143677,00     80,00  2004/2005\n",
       "...     ...  ...        ...       ...        ...\n",
       "2424   2019   20      96,00     40,00  2018/2019\n",
       "2425   2020   20      70,00     35,00  2019/2020\n",
       "2426   2021   20      97,00     65,00  2020/2021\n",
       "2427   2022   20      80,00     65,00  2021/2022\n",
       "2428   2023   20      60,00     40,00  2022/2023\n",
       "\n",
       "[2149 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vapor pressure deficit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\AppData\\Local\\Temp\\ipykernel_1364\\3789123208.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  vpd_raw = pd.concat([vpd_raw, vpd_dep]) #concat data\n"
     ]
    }
   ],
   "source": [
    "vpd_raw = pd.DataFrame(columns=[\"dep\", \"date\", \"vpd_max\", \"vpd_min\", \"vpd_mean\"])\n",
    "for vpd_file in os.listdir(f\"{VPD_DATA_URL}/dailyDepDatas/\"): #loop throught files\n",
    "    vpd_dep = pd.read_json(f\"{VPD_DATA_URL}/dailyDepDatas/{vpd_file}\") #read json\n",
    "    vpd_raw = pd.concat([vpd_raw, vpd_dep]) #concat data\n",
    "vpd_raw['DEP'] = vpd_raw['dep'].map(departements) #map dep name to dep code\n",
    "vpd_raw[\"YEAR-MONTH\"] = pd.to_datetime(vpd_raw[\"date\"]).dt.to_period('M') #new column with YYYY-MM format\n",
    "vpdMeanGroupedDepMonth = vpd_raw[[\"vpd_max\", \"vpd_min\", \"vpd_mean\", \"YEAR-MONTH\", \"DEP\"]].groupby([\"YEAR-MONTH\", \"DEP\"]).mean() #group by year-month and dep then mean the values\n",
    "vpd = vpdMeanGroupedDepMonth.reset_index() #remove multi indexing \n",
    "vpd = vpd.dropna() #removes nan values (when nan value, there is no data for the dep)\n",
    "vpd[\"YEAR\"] = vpd[\"YEAR-MONTH\"].dt.year\n",
    "vpd[\"MONTH\"] = vpd[\"YEAR-MONTH\"].dt.month\n",
    "vpd[\"MY\"] = vpd.apply(get_market_year, axis=1) #add year, month and market year for merging \n",
    "vpd = vpd[vpd[\"MY\"] >= \"1979/1980\"] #-> final vpd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpd_pivot = vpd.pivot_table( # pivot table for month datas as columns and not rows\n",
    "    index=['DEP', 'MY'],\n",
    "    columns='MONTH',\n",
    "    values=['vpd_mean', 'vpd_min', 'vpd_max']\n",
    ")\n",
    "\n",
    "vpd_pivot.columns = [ # rename columns with month number\n",
    "    f\"{col[0]}{col[1]}\" if isinstance(col, tuple) and col[1] != \"\" \n",
    "    else col for col in vpd_pivot.columns\n",
    "]\n",
    "vpd_pivot = vpd_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhanced Vegetation Index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\AppData\\Local\\Temp\\ipykernel_1364\\33089076.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  evi = pd.concat([evi, evi_dep]) #concat data\n"
     ]
    }
   ],
   "source": [
    "evi = pd.DataFrame(columns=[\"name\", \"code\", \"date\", \"mean_data\"]) \n",
    "for evi_file in os.listdir(f\"{EVI_DATA_URL}/monthlyDepMean/\"): #loop throught files\n",
    "    evi_dep = pd.read_json(f\"{EVI_DATA_URL}/monthlyDepMean/{evi_file}\") #read json\n",
    "    evi = pd.concat([evi, evi_dep]) #concat data\n",
    "evi[\"YEAR-MONTH\"] = pd.to_datetime(evi[\"date\"]).dt.to_period('M') #set period (already to monthly data but we keep same format for every dataset (Year-Month))\n",
    "evi = evi.rename(columns={\"code\": \"DEP\", \"mean_data\": \"evi\"}) #rename for same format\n",
    "evi = evi[[\"YEAR-MONTH\", \"DEP\", \"evi\"]].sort_values(by=\"YEAR-MONTH\") #keep wanted data \n",
    "evi[\"YEAR\"] = evi[\"YEAR-MONTH\"].dt.year\n",
    "evi[\"MONTH\"] = evi[\"YEAR-MONTH\"].dt.month\n",
    "evi[\"MY\"] = evi.apply(get_market_year, axis=1) #add year, month and market year for merging \n",
    "evi = evi[evi[\"MY\"] >= \"2000/2001\"] #-> final evi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "evi_pivot = evi.pivot_table( # pivot table for month datas as columns and not rows\n",
    "    index=['DEP', 'MY'],\n",
    "    columns='MONTH',\n",
    "    values=['evi']\n",
    ")\n",
    "\n",
    "evi_pivot.columns = [ # rename columns with month number\n",
    "    f\"{col[0]}{col[1]}\" if isinstance(col, tuple) and col[1] != \"\" \n",
    "    else col for col in evi_pivot.columns\n",
    "]\n",
    "evi_pivot = evi_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soil Organic Matter data (Particulate organic matter (POM) and Mineral-associated organic matter (MAOM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_pom = pd.read_json(f\"{SOM_DATA_URL}/pom.json\") #read json\n",
    "som_pom['DEP'] = som_pom['nom'].map(departements) #map dep name to dep codevpd['DEP'] = vpd['dep'].map(departements) #map dep name to dep code\n",
    "som_pom = som_pom.drop(\"nom\", axis=1) #remove unwanted dep name -> final som pom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "maom_pom = pd.read_json(f\"{SOM_DATA_URL}/maom.json\") #read json\n",
    "maom_pom['DEP'] = maom_pom['nom'].map(departements) #map dep name to dep codevpd['DEP'] = vpd['dep'].map(departements) #map dep name to dep code\n",
    "maom_pom = maom_pom.drop(\"nom\", axis=1) #remove unwanted dep name -> final som maom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "awc = pd.read_json(f\"{AWC_DATA_URL}/AWC.json\") #read json\n",
    "awc['DEP'] = awc['nom'].map(departements) #map dep name to dep codevpd['DEP'] = vpd['dep'].map(departements) #map dep name to dep code\n",
    "awc = awc.drop(\"nom\", axis=1) #remove unwanted dep name -> final AWC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = yields.merge(weather_pivot, on=['DEP', 'MY'], how='left')\n",
    "result = result.merge(vpd_pivot, on=['DEP', 'MY'], how='left')\n",
    "result = result.merge(evi_pivot, on=['DEP', 'MY'], how='left')\n",
    "\n",
    "result = result.merge(som_pom, on=\"DEP\", how=\"left\")\n",
    "result = result.merge(maom_pom, on=\"DEP\", how=\"left\")\n",
    "result = result.merge(awc, on=\"DEP\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANNEE</th>\n",
       "      <th>DEP</th>\n",
       "      <th>CULT_SURF</th>\n",
       "      <th>CULT_REND</th>\n",
       "      <th>MY</th>\n",
       "      <th>RR1</th>\n",
       "      <th>RR2</th>\n",
       "      <th>RR3</th>\n",
       "      <th>RR4</th>\n",
       "      <th>RR5</th>\n",
       "      <th>...</th>\n",
       "      <th>evi6</th>\n",
       "      <th>evi7</th>\n",
       "      <th>evi8</th>\n",
       "      <th>evi9</th>\n",
       "      <th>evi10</th>\n",
       "      <th>evi11</th>\n",
       "      <th>evi12</th>\n",
       "      <th>pom</th>\n",
       "      <th>maom</th>\n",
       "      <th>vpd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>77</td>\n",
       "      <td>134939,00</td>\n",
       "      <td>75,00</td>\n",
       "      <td>2000/2001</td>\n",
       "      <td>2.467359</td>\n",
       "      <td>1.665315</td>\n",
       "      <td>4.451066</td>\n",
       "      <td>3.182373</td>\n",
       "      <td>1.444451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514345</td>\n",
       "      <td>0.409490</td>\n",
       "      <td>0.408823</td>\n",
       "      <td>0.339984</td>\n",
       "      <td>0.291674</td>\n",
       "      <td>0.235035</td>\n",
       "      <td>0.212440</td>\n",
       "      <td>4.415719</td>\n",
       "      <td>15.990197</td>\n",
       "      <td>0.089862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>77</td>\n",
       "      <td>139375,00</td>\n",
       "      <td>85,00</td>\n",
       "      <td>2001/2002</td>\n",
       "      <td>1.109455</td>\n",
       "      <td>3.514409</td>\n",
       "      <td>1.819132</td>\n",
       "      <td>0.517874</td>\n",
       "      <td>1.712458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538276</td>\n",
       "      <td>0.448189</td>\n",
       "      <td>0.357645</td>\n",
       "      <td>0.332362</td>\n",
       "      <td>0.295205</td>\n",
       "      <td>0.288137</td>\n",
       "      <td>0.233184</td>\n",
       "      <td>4.415719</td>\n",
       "      <td>15.990197</td>\n",
       "      <td>0.089862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>77</td>\n",
       "      <td>137375,00</td>\n",
       "      <td>68,98</td>\n",
       "      <td>2002/2003</td>\n",
       "      <td>2.282796</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>0.567346</td>\n",
       "      <td>1.439708</td>\n",
       "      <td>2.846067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574613</td>\n",
       "      <td>0.407363</td>\n",
       "      <td>0.342762</td>\n",
       "      <td>0.336154</td>\n",
       "      <td>0.278275</td>\n",
       "      <td>0.217687</td>\n",
       "      <td>0.226608</td>\n",
       "      <td>4.415719</td>\n",
       "      <td>15.990197</td>\n",
       "      <td>0.089862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>77</td>\n",
       "      <td>141446,00</td>\n",
       "      <td>90,00</td>\n",
       "      <td>2003/2004</td>\n",
       "      <td>3.744067</td>\n",
       "      <td>0.405788</td>\n",
       "      <td>1.242569</td>\n",
       "      <td>2.203571</td>\n",
       "      <td>1.870232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575383</td>\n",
       "      <td>0.458860</td>\n",
       "      <td>0.353065</td>\n",
       "      <td>0.313528</td>\n",
       "      <td>0.289102</td>\n",
       "      <td>0.234515</td>\n",
       "      <td>0.204609</td>\n",
       "      <td>4.415719</td>\n",
       "      <td>15.990197</td>\n",
       "      <td>0.089862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>77</td>\n",
       "      <td>143677,00</td>\n",
       "      <td>80,00</td>\n",
       "      <td>2004/2005</td>\n",
       "      <td>1.648856</td>\n",
       "      <td>1.444091</td>\n",
       "      <td>1.541701</td>\n",
       "      <td>1.838061</td>\n",
       "      <td>1.716598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580532</td>\n",
       "      <td>0.428030</td>\n",
       "      <td>0.373774</td>\n",
       "      <td>0.340361</td>\n",
       "      <td>0.277447</td>\n",
       "      <td>0.248891</td>\n",
       "      <td>0.204195</td>\n",
       "      <td>4.415719</td>\n",
       "      <td>15.990197</td>\n",
       "      <td>0.089862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>2019</td>\n",
       "      <td>20</td>\n",
       "      <td>96,00</td>\n",
       "      <td>40,00</td>\n",
       "      <td>2018/2019</td>\n",
       "      <td>1.825853</td>\n",
       "      <td>2.234225</td>\n",
       "      <td>0.470323</td>\n",
       "      <td>2.643190</td>\n",
       "      <td>3.537650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399499</td>\n",
       "      <td>0.388429</td>\n",
       "      <td>0.377462</td>\n",
       "      <td>0.375772</td>\n",
       "      <td>0.352461</td>\n",
       "      <td>0.336898</td>\n",
       "      <td>0.322346</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>2020</td>\n",
       "      <td>20</td>\n",
       "      <td>70,00</td>\n",
       "      <td>35,00</td>\n",
       "      <td>2019/2020</td>\n",
       "      <td>1.687465</td>\n",
       "      <td>0.514343</td>\n",
       "      <td>2.962535</td>\n",
       "      <td>3.276762</td>\n",
       "      <td>2.581244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.431090</td>\n",
       "      <td>0.388402</td>\n",
       "      <td>0.355846</td>\n",
       "      <td>0.336295</td>\n",
       "      <td>0.313358</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>2021</td>\n",
       "      <td>20</td>\n",
       "      <td>97,00</td>\n",
       "      <td>65,00</td>\n",
       "      <td>2020/2021</td>\n",
       "      <td>5.630784</td>\n",
       "      <td>2.620412</td>\n",
       "      <td>1.022414</td>\n",
       "      <td>1.969150</td>\n",
       "      <td>2.378431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405275</td>\n",
       "      <td>0.392680</td>\n",
       "      <td>0.360204</td>\n",
       "      <td>0.371781</td>\n",
       "      <td>0.375880</td>\n",
       "      <td>0.340750</td>\n",
       "      <td>0.330526</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>2022</td>\n",
       "      <td>20</td>\n",
       "      <td>80,00</td>\n",
       "      <td>65,00</td>\n",
       "      <td>2021/2022</td>\n",
       "      <td>0.921650</td>\n",
       "      <td>0.828915</td>\n",
       "      <td>1.524876</td>\n",
       "      <td>3.056282</td>\n",
       "      <td>1.225617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403204</td>\n",
       "      <td>0.379189</td>\n",
       "      <td>0.366802</td>\n",
       "      <td>0.343552</td>\n",
       "      <td>0.334657</td>\n",
       "      <td>0.288043</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>2023</td>\n",
       "      <td>20</td>\n",
       "      <td>60,00</td>\n",
       "      <td>40,00</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>4.384367</td>\n",
       "      <td>2.767651</td>\n",
       "      <td>1.613400</td>\n",
       "      <td>1.570661</td>\n",
       "      <td>2.727481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417501</td>\n",
       "      <td>0.382688</td>\n",
       "      <td>0.369777</td>\n",
       "      <td>0.350959</td>\n",
       "      <td>0.324504</td>\n",
       "      <td>0.316170</td>\n",
       "      <td>0.319895</td>\n",
       "      <td>15.657990</td>\n",
       "      <td>28.322897</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ANNEE  DEP  CULT_SURF CULT_REND         MY       RR1       RR2  \\\n",
       "0      2001   77  134939,00     75,00  2000/2001  2.467359  1.665315   \n",
       "1      2002   77  139375,00     85,00  2001/2002  1.109455  3.514409   \n",
       "2      2003   77  137375,00     68,98  2002/2003  2.282796  0.926441   \n",
       "3      2004   77  141446,00     90,00  2003/2004  3.744067  0.405788   \n",
       "4      2005   77  143677,00     80,00  2004/2005  1.648856  1.444091   \n",
       "...     ...  ...        ...       ...        ...       ...       ...   \n",
       "2144   2019   20      96,00     40,00  2018/2019  1.825853  2.234225   \n",
       "2145   2020   20      70,00     35,00  2019/2020  1.687465  0.514343   \n",
       "2146   2021   20      97,00     65,00  2020/2021  5.630784  2.620412   \n",
       "2147   2022   20      80,00     65,00  2021/2022  0.921650  0.828915   \n",
       "2148   2023   20      60,00     40,00  2022/2023  4.384367  2.767651   \n",
       "\n",
       "           RR3       RR4       RR5  ...      evi6      evi7      evi8  \\\n",
       "0     4.451066  3.182373  1.444451  ...  0.514345  0.409490  0.408823   \n",
       "1     1.819132  0.517874  1.712458  ...  0.538276  0.448189  0.357645   \n",
       "2     0.567346  1.439708  2.846067  ...  0.574613  0.407363  0.342762   \n",
       "3     1.242569  2.203571  1.870232  ...  0.575383  0.458860  0.353065   \n",
       "4     1.541701  1.838061  1.716598  ...  0.580532  0.428030  0.373774   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2144  0.470323  2.643190  3.537650  ...  0.399499  0.388429  0.377462   \n",
       "2145  2.962535  3.276762  2.581244  ...  0.435666  0.431090  0.388402   \n",
       "2146  1.022414  1.969150  2.378431  ...  0.405275  0.392680  0.360204   \n",
       "2147  1.524876  3.056282  1.225617  ...  0.403204  0.379189  0.366802   \n",
       "2148  1.613400  1.570661  2.727481  ...  0.417501  0.382688  0.369777   \n",
       "\n",
       "          evi9     evi10     evi11     evi12        pom       maom       vpd  \n",
       "0     0.339984  0.291674  0.235035  0.212440   4.415719  15.990197  0.089862  \n",
       "1     0.332362  0.295205  0.288137  0.233184   4.415719  15.990197  0.089862  \n",
       "2     0.336154  0.278275  0.217687  0.226608   4.415719  15.990197  0.089862  \n",
       "3     0.313528  0.289102  0.234515  0.204609   4.415719  15.990197  0.089862  \n",
       "4     0.340361  0.277447  0.248891  0.204195   4.415719  15.990197  0.089862  \n",
       "...        ...       ...       ...       ...        ...        ...       ...  \n",
       "2144  0.375772  0.352461  0.336898  0.322346  15.657990  28.322897  0.109897  \n",
       "2145  0.355846  0.336295  0.313358  0.300604  15.657990  28.322897  0.109897  \n",
       "2146  0.371781  0.375880  0.340750  0.330526  15.657990  28.322897  0.109897  \n",
       "2147  0.343552  0.334657  0.288043  0.291791  15.657990  28.322897  0.109897  \n",
       "2148  0.350959  0.324504  0.316170  0.319895  15.657990  28.322897  0.109897  \n",
       "\n",
       "[2149 rows x 104 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"wheat_model_dataset_2001_2023.csv\", index=False) #dataset to csv ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
